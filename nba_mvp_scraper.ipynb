{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f221551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70b768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b84089e3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up logging with more detailed format\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97233189",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class NBADataScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.basketball-reference.com\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "    def get_page_content(self, url):\n",
    "        \"\"\"Fetch page content with error handling and rate limiting\"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Fetching URL: {url}\")\n",
    "            time.sleep(3)  # Rate limiting\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.content, 'html.parser')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Request error for {url}: {str(e)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error fetching {url}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_mvp_winner(self, year):\n",
    "        \"\"\"Extract MVP winner for a given season\"\"\"\n",
    "        url = f\"{self.base_url}/awards/awards_{year}.html\"\n",
    "        soup = self.get_page_content(url)\n",
    "        if not soup:\n",
    "            logging.error(f\"Failed to get MVP page for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            mvp_table = soup.find('table', {'id': 'mvp'})\n",
    "            if not mvp_table:\n",
    "                logging.error(f\"Could not find MVP table for {year}\")\n",
    "                return None\n",
    "                \n",
    "            # Get the first row (winner)\n",
    "            winner_row = mvp_table.find('tbody').find('tr')\n",
    "            if not winner_row:\n",
    "                logging.error(f\"Could not find MVP winner row for {year}\")\n",
    "                return None\n",
    "                \n",
    "            player_name = winner_row.find('td', {'data-stat': 'player'}).text.strip()\n",
    "            logging.info(f\"Found MVP winner for {year}: {player_name}\")\n",
    "            return player_name\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting MVP winner for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_basic_stats(self, year):\n",
    "        \"\"\"Extract basic statistics for a given season\"\"\"\n",
    "        url = f\"{self.base_url}/leagues/NBA_{year}_per_game.html\"\n",
    "        soup = self.get_page_content(url)\n",
    "        if not soup:\n",
    "            logging.error(f\"Failed to get basic stats page for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            stats_table = soup.find('table', {'id': 'per_game_stats'})\n",
    "            if not stats_table:\n",
    "                logging.error(f\"Could not find basic stats table for {year}\")\n",
    "                return None\n",
    "                \n",
    "            # Convert table to DataFrame\n",
    "            df = pd.read_html(str(stats_table))[0]\n",
    "            \n",
    "            # Print available columns for debugging\n",
    "            logging.info(f\"Available columns for {year}: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Clean up the DataFrame\n",
    "            df = df[df['Player'].notna()]  # Remove rows where Player is NaN\n",
    "            df = df[~df['Player'].str.contains('Player')]  # Remove header rows\n",
    "            \n",
    "            # Map column names to handle different naming conventions\n",
    "            column_mapping = {\n",
    "                'Tm': 'Team',\n",
    "                'Pos': 'Position',\n",
    "                'G': 'Games',\n",
    "                'MP': 'Minutes',\n",
    "                'PTS': 'Points',\n",
    "                'TRB': 'Rebounds',\n",
    "                'AST': 'Assists',\n",
    "                'STL': 'Steals',\n",
    "                'BLK': 'Blocks',\n",
    "                'TOV': 'Turnovers',\n",
    "                'FG%': 'FG_Pct',\n",
    "                '3P%': '3P_Pct',\n",
    "                'FT%': 'FT_Pct'\n",
    "            }\n",
    "            \n",
    "            # Rename columns if they exist\n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in df.columns:\n",
    "                    df = df.rename(columns={old_col: new_col})\n",
    "            \n",
    "            # Select relevant columns (using new names)\n",
    "            columns = ['Player', 'Team', 'Position', 'Games', 'Minutes', 'Points', \n",
    "                      'Rebounds', 'Assists', 'Steals', 'Blocks', 'Turnovers', \n",
    "                      'FG_Pct', '3P_Pct', 'FT_Pct']\n",
    "            \n",
    "            # Only select columns that exist in the DataFrame\n",
    "            available_columns = [col for col in columns if col in df.columns]\n",
    "            if not available_columns:\n",
    "                logging.error(f\"No matching columns found for {year}\")\n",
    "                return None\n",
    "                \n",
    "            df = df[available_columns]\n",
    "            logging.info(f\"Successfully extracted basic stats for {year}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting basic stats for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_advanced_stats(self, year):\n",
    "        \"\"\"Extract advanced statistics for a given season\"\"\"\n",
    "        url = f\"{self.base_url}/leagues/NBA_{year}_advanced.html\"\n",
    "        soup = self.get_page_content(url)\n",
    "        if not soup:\n",
    "            logging.error(f\"Failed to get advanced stats page for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Look for the table with class 'stats_table'\n",
    "            stats_table = soup.find('table', {'class': 'stats_table'})\n",
    "            if not stats_table:\n",
    "                logging.error(f\"Could not find advanced stats table for {year}\")\n",
    "                return None\n",
    "                \n",
    "            # Convert table to DataFrame\n",
    "            df = pd.read_html(str(stats_table))[0]\n",
    "            \n",
    "            # Print available columns for debugging\n",
    "            logging.info(f\"Available advanced columns for {year}: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Clean up the DataFrame\n",
    "            df = df[df['Player'].notna()]  # Remove rows where Player is NaN\n",
    "            df = df[~df['Player'].str.contains('Player')]  # Remove header rows\n",
    "            \n",
    "            # Map column names to handle different naming conventions\n",
    "            column_mapping = {\n",
    "                'PER': 'Player_Efficiency_Rating',\n",
    "                'WS': 'Win_Shares',\n",
    "                'BPM': 'Box_Plus_Minus',\n",
    "                'USG%': 'Usage_Rate',\n",
    "                'VORP': 'Value_Over_Replacement',\n",
    "                'WS/48': 'Win_Shares_Per_48'\n",
    "            }\n",
    "            \n",
    "            # Rename columns if they exist\n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in df.columns:\n",
    "                    df = df.rename(columns={old_col: new_col})\n",
    "            \n",
    "            # Select relevant columns (using new names)\n",
    "            columns = ['Player', 'Player_Efficiency_Rating', 'Win_Shares', \n",
    "                      'Box_Plus_Minus', 'Usage_Rate', 'Value_Over_Replacement', \n",
    "                      'Win_Shares_Per_48']\n",
    "            \n",
    "            # Only select columns that exist in the DataFrame\n",
    "            available_columns = [col for col in columns if col in df.columns]\n",
    "            if not available_columns:\n",
    "                logging.error(f\"No matching advanced columns found for {year}\")\n",
    "                return None\n",
    "                \n",
    "            df = df[available_columns]\n",
    "            logging.info(f\"Successfully extracted advanced stats for {year}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting advanced stats for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_season(self, year):\n",
    "        \"\"\"Scrape all data for a given season\"\"\"\n",
    "        logging.info(f\"Starting to scrape data for {year} season...\")\n",
    "        \n",
    "        # Get MVP winner\n",
    "        mvp_winner = self.get_mvp_winner(year)\n",
    "        if mvp_winner is None:\n",
    "            logging.error(f\"Failed to get MVP winner for {year}\")\n",
    "            return None\n",
    "        \n",
    "        # Get basic stats\n",
    "        basic_stats = self.get_basic_stats(year)\n",
    "        if basic_stats is None:\n",
    "            logging.error(f\"Failed to get basic stats for {year}\")\n",
    "            return None\n",
    "            \n",
    "        # Get advanced stats\n",
    "        advanced_stats = self.get_advanced_stats(year)\n",
    "        if advanced_stats is None:\n",
    "            logging.error(f\"Failed to get advanced stats for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Merge basic and advanced stats\n",
    "            merged_stats = pd.merge(basic_stats, advanced_stats, on='Player', how='left')\n",
    "            \n",
    "            # Add MVP column\n",
    "            merged_stats['MVP'] = merged_stats['Player'].apply(lambda x: 1 if x == mvp_winner else 0)\n",
    "            \n",
    "            logging.info(f\"Successfully merged all data for {year}\")\n",
    "            return merged_stats\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error merging data for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_all_seasons(self, start_year=1981, end_year=2024):\n",
    "        \"\"\"Scrape data for all seasons in the given range\"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        for year in tqdm(range(start_year, end_year + 1), desc=\"Scraping seasons\"):\n",
    "            season_data = self.scrape_season(year)\n",
    "            if season_data is not None:\n",
    "                all_data.append(season_data)\n",
    "                logging.info(f\"Successfully scraped {year} season\")\n",
    "            else:\n",
    "                logging.error(f\"Failed to scrape {year} season\")\n",
    "                \n",
    "        if not all_data:\n",
    "            logging.error(\"No data was collected!\")\n",
    "            return None\n",
    "            \n",
    "        # Combine all seasons\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Clean up the final DataFrame\n",
    "        final_df = final_df.fillna(0)  # Fill missing values with 0\n",
    "        \n",
    "        # Ensure all numeric columns are float\n",
    "        numeric_columns = ['Minutes', 'Points', 'Rebounds', 'Assists', 'Steals', \n",
    "                         'Blocks', 'Turnovers', 'FG_Pct', '3P_Pct', 'FT_Pct', \n",
    "                         'Player_Efficiency_Rating', 'Win_Shares', 'Box_Plus_Minus', \n",
    "                         'Usage_Rate', 'Value_Over_Replacement', 'Win_Shares_Per_48']\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            if col in final_df.columns:\n",
    "                final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "        \n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc76bc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    scraper = NBADataScraper()\n",
    "    final_df = scraper.scrape_all_seasons()\n",
    "    \n",
    "    if final_df is not None:\n",
    "        # Save to CSV\n",
    "        output_file = 'nba_mvp_data_NEW.csv'\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Data successfully saved to {output_file}\")\n",
    "        \n",
    "        # Print some basic statistics about the dataset\n",
    "        logging.info(f\"\\nDataset Statistics:\")\n",
    "        logging.info(f\"Total number of player-seasons: {len(final_df)}\")\n",
    "        logging.info(f\"Number of MVP winners: {final_df['MVP'].sum()}\")\n",
    "        logging.info(f\"Seasons covered: {final_df['Season'].min()} to {final_df['Season'].max()}\")\n",
    "    else:\n",
    "        logging.error(\"Failed to create the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d595a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping seasons:   0%|          | 0/44 [00:00<?, ?it/s]2025-05-09 17:15:13,999 - INFO - Starting to scrape data for 1981 season...\n",
      "2025-05-09 17:15:13,999 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1981.html\n",
      "2025-05-09 17:15:17,233 - INFO - Found MVP winner for 1981: Julius Erving\n",
      "2025-05-09 17:15:17,234 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1981_per_game.html\n",
      "2025-05-09 17:15:20,843 - INFO - Available columns for 1981: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:15:20,845 - INFO - Successfully extracted basic stats for 1981\n",
      "2025-05-09 17:15:20,845 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1981_advanced.html\n",
      "2025-05-09 17:15:24,469 - INFO - Available advanced columns for 1981: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:15:24,471 - INFO - Successfully extracted advanced stats for 1981\n",
      "2025-05-09 17:15:24,472 - INFO - Successfully merged all data for 1981\n",
      "2025-05-09 17:15:24,472 - INFO - Successfully scraped 1981 season\n",
      "Scraping seasons:   2%|▏         | 1/44 [00:10<07:30, 10.47s/it]2025-05-09 17:15:24,473 - INFO - Starting to scrape data for 1982 season...\n",
      "2025-05-09 17:15:24,473 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1982.html\n",
      "2025-05-09 17:15:27,672 - INFO - Found MVP winner for 1982: Moses Malone\n",
      "2025-05-09 17:15:27,672 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1982_per_game.html\n",
      "2025-05-09 17:15:31,338 - INFO - Available columns for 1982: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:15:31,339 - INFO - Successfully extracted basic stats for 1982\n",
      "2025-05-09 17:15:31,339 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1982_advanced.html\n",
      "2025-05-09 17:15:34,944 - INFO - Available advanced columns for 1982: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:15:34,945 - INFO - Successfully extracted advanced stats for 1982\n",
      "2025-05-09 17:15:34,947 - INFO - Successfully merged all data for 1982\n",
      "2025-05-09 17:15:34,947 - INFO - Successfully scraped 1982 season\n",
      "Scraping seasons:   5%|▍         | 2/44 [00:20<07:19, 10.47s/it]2025-05-09 17:15:34,947 - INFO - Starting to scrape data for 1983 season...\n",
      "2025-05-09 17:15:34,947 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1983.html\n",
      "2025-05-09 17:15:38,153 - INFO - Found MVP winner for 1983: Moses Malone\n",
      "2025-05-09 17:15:38,153 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1983_per_game.html\n",
      "2025-05-09 17:15:41,795 - INFO - Available columns for 1983: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:15:41,797 - INFO - Successfully extracted basic stats for 1983\n",
      "2025-05-09 17:15:41,797 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1983_advanced.html\n",
      "2025-05-09 17:15:45,437 - INFO - Available advanced columns for 1983: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:15:45,438 - INFO - Successfully extracted advanced stats for 1983\n",
      "2025-05-09 17:15:45,440 - INFO - Successfully merged all data for 1983\n",
      "2025-05-09 17:15:45,440 - INFO - Successfully scraped 1983 season\n",
      "Scraping seasons:   7%|▋         | 3/44 [00:31<07:09, 10.48s/it]2025-05-09 17:15:45,440 - INFO - Starting to scrape data for 1984 season...\n",
      "2025-05-09 17:15:45,440 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1984.html\n",
      "2025-05-09 17:15:48,638 - INFO - Found MVP winner for 1984: Larry Bird\n",
      "2025-05-09 17:15:48,639 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1984_per_game.html\n",
      "2025-05-09 17:15:52,711 - INFO - Available columns for 1984: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:15:52,715 - INFO - Successfully extracted basic stats for 1984\n",
      "2025-05-09 17:15:52,716 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1984_advanced.html\n",
      "2025-05-09 17:15:56,328 - INFO - Available advanced columns for 1984: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:15:56,329 - INFO - Successfully extracted advanced stats for 1984\n",
      "2025-05-09 17:15:56,330 - INFO - Successfully merged all data for 1984\n",
      "2025-05-09 17:15:56,330 - INFO - Successfully scraped 1984 season\n",
      "Scraping seasons:   9%|▉         | 4/44 [00:42<07:05, 10.64s/it]2025-05-09 17:15:56,331 - INFO - Starting to scrape data for 1985 season...\n",
      "2025-05-09 17:15:56,331 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1985.html\n",
      "2025-05-09 17:15:59,691 - INFO - Found MVP winner for 1985: Larry Bird\n",
      "2025-05-09 17:15:59,691 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1985_per_game.html\n",
      "2025-05-09 17:16:03,314 - INFO - Available columns for 1985: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:16:03,315 - INFO - Successfully extracted basic stats for 1985\n",
      "2025-05-09 17:16:03,316 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1985_advanced.html\n",
      "2025-05-09 17:16:06,989 - INFO - Available advanced columns for 1985: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:16:06,990 - INFO - Successfully extracted advanced stats for 1985\n",
      "2025-05-09 17:16:06,992 - INFO - Successfully merged all data for 1985\n",
      "2025-05-09 17:16:06,992 - INFO - Successfully scraped 1985 season\n",
      "Scraping seasons:  11%|█▏        | 5/44 [00:52<06:55, 10.65s/it]2025-05-09 17:16:06,992 - INFO - Starting to scrape data for 1986 season...\n",
      "2025-05-09 17:16:06,992 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1986.html\n",
      "2025-05-09 17:16:10,299 - INFO - Found MVP winner for 1986: Larry Bird\n",
      "2025-05-09 17:16:10,299 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1986_per_game.html\n",
      "2025-05-09 17:16:13,919 - INFO - Available columns for 1986: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:16:13,921 - INFO - Successfully extracted basic stats for 1986\n",
      "2025-05-09 17:16:13,921 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1986_advanced.html\n",
      "2025-05-09 17:16:17,516 - INFO - Available advanced columns for 1986: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:16:17,517 - INFO - Successfully extracted advanced stats for 1986\n",
      "2025-05-09 17:16:17,519 - INFO - Successfully merged all data for 1986\n",
      "2025-05-09 17:16:17,519 - INFO - Successfully scraped 1986 season\n",
      "Scraping seasons:  14%|█▎        | 6/44 [01:03<06:43, 10.61s/it]2025-05-09 17:16:17,519 - INFO - Starting to scrape data for 1987 season...\n",
      "2025-05-09 17:16:17,519 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1987.html\n",
      "2025-05-09 17:16:20,736 - INFO - Found MVP winner for 1987: Magic Johnson\n",
      "2025-05-09 17:16:20,736 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1987_per_game.html\n",
      "2025-05-09 17:16:24,248 - INFO - Available columns for 1987: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:16:24,249 - INFO - Successfully extracted basic stats for 1987\n",
      "2025-05-09 17:16:24,250 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1987_advanced.html\n",
      "2025-05-09 17:16:27,819 - INFO - Available advanced columns for 1987: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:16:27,820 - INFO - Successfully extracted advanced stats for 1987\n",
      "2025-05-09 17:16:27,821 - INFO - Successfully merged all data for 1987\n",
      "2025-05-09 17:16:27,821 - INFO - Successfully scraped 1987 season\n",
      "Scraping seasons:  16%|█▌        | 7/44 [01:13<06:28, 10.51s/it]2025-05-09 17:16:27,822 - INFO - Starting to scrape data for 1988 season...\n",
      "2025-05-09 17:16:27,822 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1988.html\n",
      "2025-05-09 17:16:30,951 - INFO - Found MVP winner for 1988: Michael Jordan\n",
      "2025-05-09 17:16:30,952 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1988_per_game.html\n",
      "2025-05-09 17:16:34,577 - INFO - Available columns for 1988: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:16:34,578 - INFO - Successfully extracted basic stats for 1988\n",
      "2025-05-09 17:16:34,579 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1988_advanced.html\n",
      "2025-05-09 17:16:38,219 - INFO - Available advanced columns for 1988: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-09 17:16:38,220 - INFO - Successfully extracted advanced stats for 1988\n",
      "2025-05-09 17:16:38,221 - INFO - Successfully merged all data for 1988\n",
      "2025-05-09 17:16:38,221 - INFO - Successfully scraped 1988 season\n",
      "Scraping seasons:  18%|█▊        | 8/44 [01:24<06:17, 10.47s/it]2025-05-09 17:16:38,222 - INFO - Starting to scrape data for 1989 season...\n",
      "2025-05-09 17:16:38,222 - INFO - Fetching URL: https://www.basketball-reference.com/awards/awards_1989.html\n",
      "2025-05-09 17:16:41,423 - INFO - Found MVP winner for 1989: Magic Johnson\n",
      "2025-05-09 17:16:41,424 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1989_per_game.html\n",
      "2025-05-09 17:16:45,032 - INFO - Available columns for 1989: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-09 17:16:45,034 - INFO - Successfully extracted basic stats for 1989\n",
      "2025-05-09 17:16:45,034 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_1989_advanced.html\n",
      "Scraping seasons:  18%|█▊        | 8/44 [01:32<06:56, 11.57s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      2\u001b[39m     scraper = NBADataScraper()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     final_df = \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscrape_all_seasons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m final_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m      7\u001b[39m         output_file = \u001b[33m'\u001b[39m\u001b[33mnba_mvp_data_NEW.csv\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 212\u001b[39m, in \u001b[36mNBADataScraper.scrape_all_seasons\u001b[39m\u001b[34m(self, start_year, end_year)\u001b[39m\n\u001b[32m    209\u001b[39m all_data = []\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(start_year, end_year + \u001b[32m1\u001b[39m), desc=\u001b[33m\"\u001b[39m\u001b[33mScraping seasons\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     season_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscrape_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m season_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m         all_data.append(season_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mNBADataScraper.scrape_season\u001b[39m\u001b[34m(self, year)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Get advanced stats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m advanced_stats = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_advanced_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m advanced_stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    191\u001b[39m     logging.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to get advanced stats for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mNBADataScraper.get_advanced_stats\u001b[39m\u001b[34m(self, year)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extract advanced statistics for a given season\"\"\"\u001b[39;00m\n\u001b[32m    116\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/leagues/NBA_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_advanced.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m soup = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_page_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m soup:\n\u001b[32m    119\u001b[39m     logging.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to get advanced stats page for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mNBADataScraper.get_page_content\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     11\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     time.sleep(\u001b[32m3\u001b[39m)  \u001b[38;5;66;03m# Rate limiting\u001b[39;00m\n\u001b[32m     13\u001b[39m     response = requests.get(url, headers=\u001b[38;5;28mself\u001b[39m.headers)\n\u001b[32m     14\u001b[39m     response.raise_for_status()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
