{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615976d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094b7298",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up logging with more detailed format\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7af772",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class NBADataScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.basketball-reference.com\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "    def get_page_content(self, url):\n",
    "        \"\"\"Fetch page content with error handling and rate limiting\"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Fetching URL: {url}\")\n",
    "            time.sleep(3)  # Rate limiting\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.content, 'html.parser')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Request error for {url}: {str(e)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error fetching {url}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_basic_stats(self, year):\n",
    "        \"\"\"Extract basic statistics for a given season\"\"\"\n",
    "        url = f\"{self.base_url}/leagues/NBA_{year}_per_game.html\"\n",
    "        soup = self.get_page_content(url)\n",
    "        if not soup:\n",
    "            logging.error(f\"Failed to get basic stats page for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            stats_table = soup.find('table', {'id': 'per_game_stats'})\n",
    "            if not stats_table:\n",
    "                logging.error(f\"Could not find basic stats table for {year}\")\n",
    "                return None\n",
    "                \n",
    "            # Convert table to DataFrame\n",
    "            df = pd.read_html(str(stats_table))[0]\n",
    "            \n",
    "            # Print available columns for debugging\n",
    "            logging.info(f\"Available columns for {year}: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Clean up the DataFrame\n",
    "            df = df[df['Player'].notna()]  # Remove rows where Player is NaN\n",
    "            df = df[~df['Player'].str.contains('Player')]  # Remove header rows\n",
    "            \n",
    "            # Map column names to handle different naming conventions\n",
    "            column_mapping = {\n",
    "                'Tm': 'Team',\n",
    "                'Pos': 'Position',\n",
    "                'G': 'Games',\n",
    "                'MP': 'Minutes',\n",
    "                'PTS': 'Points',\n",
    "                'TRB': 'Rebounds',\n",
    "                'AST': 'Assists',\n",
    "                'STL': 'Steals',\n",
    "                'BLK': 'Blocks',\n",
    "                'TOV': 'Turnovers',\n",
    "                'FG%': 'FG_Pct',\n",
    "                '3P%': '3P_Pct',\n",
    "                'FT%': 'FT_Pct'\n",
    "            }\n",
    "            \n",
    "            # Rename columns if they exist\n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in df.columns:\n",
    "                    df = df.rename(columns={old_col: new_col})\n",
    "            \n",
    "            # Select relevant columns (using new names)\n",
    "            columns = ['Player', 'Team', 'Position', 'Season', 'Games', 'Minutes', 'Points', \n",
    "                      'Rebounds', 'Assists', 'Steals', 'Blocks', 'Turnovers', \n",
    "                      'FG_Pct', '3P_Pct', 'FT_Pct']\n",
    "            \n",
    "            # Only select columns that exist in the DataFrame\n",
    "            available_columns = [col for col in columns if col in df.columns]\n",
    "            if not available_columns:\n",
    "                logging.error(f\"No matching columns found for {year}\")\n",
    "                return None\n",
    "                \n",
    "            df = df[available_columns]\n",
    "            logging.info(f\"Successfully extracted basic stats for {year}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting basic stats for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_advanced_stats(self, year):\n",
    "        \"\"\"Extract advanced statistics for a given season\"\"\"\n",
    "        url = f\"{self.base_url}/leagues/NBA_{year}_advanced.html\"\n",
    "        soup = self.get_page_content(url)\n",
    "        if not soup:\n",
    "            logging.error(f\"Failed to get advanced stats page for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Look for the table with class 'stats_table'\n",
    "            stats_table = soup.find('table', {'class': 'stats_table'})\n",
    "            if not stats_table:\n",
    "                logging.error(f\"Could not find advanced stats table for {year}\")\n",
    "                return None\n",
    "                \n",
    "            # Convert table to DataFrame\n",
    "            df = pd.read_html(str(stats_table))[0]\n",
    "            \n",
    "            # Print available columns for debugging\n",
    "            logging.info(f\"Available advanced columns for {year}: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Clean up the DataFrame\n",
    "            df = df[df['Player'].notna()]  # Remove rows where Player is NaN\n",
    "            df = df[~df['Player'].str.contains('Player')]  # Remove header rows\n",
    "            \n",
    "            # Map column names to handle different naming conventions\n",
    "            column_mapping = {\n",
    "                'PER': 'Player_Efficiency_Rating',\n",
    "                'WS': 'Win_Shares',\n",
    "                'BPM': 'Box_Plus_Minus',\n",
    "                'USG%': 'Usage_Rate',\n",
    "                'VORP': 'Value_Over_Replacement',\n",
    "                'WS/48': 'Win_Shares_Per_48'\n",
    "            }\n",
    "            \n",
    "            # Rename columns if they exist\n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in df.columns:\n",
    "                    df = df.rename(columns={old_col: new_col})\n",
    "            \n",
    "            # Select relevant columns (using new names)\n",
    "            columns = ['Player', 'Player_Efficiency_Rating', 'Win_Shares', \n",
    "                      'Box_Plus_Minus', 'Usage_Rate', 'Value_Over_Replacement', \n",
    "                      'Win_Shares_Per_48']\n",
    "            \n",
    "            # Only select columns that exist in the DataFrame\n",
    "            available_columns = [col for col in columns if col in df.columns]\n",
    "            if not available_columns:\n",
    "                logging.error(f\"No matching advanced columns found for {year}\")\n",
    "                return None\n",
    "                \n",
    "            df = df[available_columns]\n",
    "            logging.info(f\"Successfully extracted advanced stats for {year}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting advanced stats for {year}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_season(self, year):\n",
    "        \"\"\"Scrape all data for a given season\"\"\"\n",
    "        logging.info(f\"Starting to scrape data for {year} season...\")\n",
    "        \n",
    "        # Get basic stats\n",
    "        basic_stats = self.get_basic_stats(year)\n",
    "        if basic_stats is None:\n",
    "            logging.error(f\"Failed to get basic stats for {year}\")\n",
    "            return None\n",
    "            \n",
    "        # Get advanced stats\n",
    "        advanced_stats = self.get_advanced_stats(year)\n",
    "        if advanced_stats is None:\n",
    "            logging.error(f\"Failed to get advanced stats for {year}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            # Merge basic and advanced stats\n",
    "            merged_stats = pd.merge(basic_stats, advanced_stats, on='Player', how='left')\n",
    "            \n",
    "            # Add Season column\n",
    "            merged_stats['Season'] = year\n",
    "            \n",
    "            logging.info(f\"Successfully merged all data for {year}\")\n",
    "            return merged_stats\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error merging data for {year}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be9d976",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    scraper = NBADataScraper()\n",
    "    year = 2025  # Only scrape 2024-2025 season\n",
    "    season_data = scraper.scrape_season(year)\n",
    "    \n",
    "    if season_data is not None:\n",
    "        # Reorder columns to put Season first\n",
    "        cols = season_data.columns.tolist()\n",
    "        cols.remove('Season')\n",
    "        cols = ['Season'] + cols\n",
    "        season_data = season_data[cols]\n",
    "        \n",
    "        # Clean up the DataFrame\n",
    "        season_data = season_data.fillna(0)  # Fill missing values with 0\n",
    "        \n",
    "        # Ensure all numeric columns are float\n",
    "        numeric_columns = ['Minutes', 'Points', 'Rebounds', 'Assists', 'Steals', \n",
    "                         'Blocks', 'Turnovers', 'FG_Pct', '3P_Pct', 'FT_Pct', \n",
    "                         'Player_Efficiency_Rating', 'Win_Shares', 'Box_Plus_Minus', \n",
    "                         'Usage_Rate', 'Value_Over_Replacement', 'Win_Shares_Per_48']\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            if col in season_data.columns:\n",
    "                season_data[col] = pd.to_numeric(season_data[col], errors='coerce')\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_file = 'nba_2025_season.csv'\n",
    "        season_data.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Data successfully saved to {output_file}\")\n",
    "        \n",
    "        # Print some basic statistics about the dataset\n",
    "        logging.info(f\"\\nDataset Statistics:\")\n",
    "        logging.info(f\"Total number of players: {len(season_data)}\")\n",
    "        logging.info(f\"Season: {year}\")\n",
    "    else:\n",
    "        logging.error(\"Failed to create the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3959b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 19:00:12,234 - INFO - Starting to scrape data for 2025 season...\n",
      "2025-05-10 19:00:12,234 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_2025_per_game.html\n",
      "2025-05-10 19:00:16,251 - INFO - Available columns for 2025: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Awards']\n",
      "2025-05-10 19:00:16,255 - INFO - Successfully extracted basic stats for 2025\n",
      "2025-05-10 19:00:16,255 - INFO - Fetching URL: https://www.basketball-reference.com/leagues/NBA_2025_advanced.html\n",
      "2025-05-10 19:00:20,230 - INFO - Available advanced columns for 2025: ['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards']\n",
      "2025-05-10 19:00:20,232 - INFO - Successfully extracted advanced stats for 2025\n",
      "2025-05-10 19:00:20,234 - INFO - Successfully merged all data for 2025\n",
      "2025-05-10 19:00:20,241 - INFO - Data successfully saved to nba_2025_season.csv\n",
      "2025-05-10 19:00:20,241 - INFO - \n",
      "Dataset Statistics:\n",
      "2025-05-10 19:00:20,242 - INFO - Total number of players: 1246\n",
      "2025-05-10 19:00:20,242 - INFO - Season: 2025\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
